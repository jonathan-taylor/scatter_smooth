{"version":"1","records":[{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline"},"type":"lvl1","url":"/compare-r","position":0},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline"},"content":"This document demonstrates the usage of the smoothing_spline package and compares it with the standard smooth.spline function in R. We will use the Bikeshare dataset from the ISLP package.","type":"content","url":"/compare-r","position":1},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Setup"},"type":"lvl2","url":"/compare-r#setup","position":2},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Setup"},"content":"First, we need to import the necessary libraries and load the rpy2 extension to run R code directly in this notebook.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time\nfrom ISLP import load_data\nfrom smoothing_spline import SplineFitter\n\n%load_ext rpy2.ipython\n\n\n\n","type":"content","url":"/compare-r#setup","position":3},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Loading the Data"},"type":"lvl2","url":"/compare-r#loading-the-data","position":4},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Loading the Data"},"content":"We will use the Bikeshare dataset, which contains daily counts of bike rentals in Washington D.C.\n\nBike = load_data('Bikeshare')\nBike.head()\n\n\n\nWe will focus on the relationship between the hour of the day (hr) and the number of bikers (bikers). Since hr is categorical in the original dataset but represents time, we convert it to numeric.\n\ndf = 7\n# 'bikers' is 'cnt' in the original dataset, ISLP might have renamed it or we use 'cnt'\nif 'bikers' not in Bike.columns:\n    Bike['bikers'] = Bike['cnt']\n\nhr_numeric = pd.to_numeric(Bike['hr'])\nbikers = Bike['bikers']\n\n# Sort by hour for cleaner plotting lines\nsorted_idx = np.argsort(hr_numeric)\nx_plot = hr_numeric.iloc[sorted_idx].unique()\n\n\n\n","type":"content","url":"/compare-r#loading-the-data","position":5},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Fitting Smoothing Splines"},"type":"lvl2","url":"/compare-r#fitting-smoothing-splines","position":6},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Fitting Smoothing Splines"},"content":"","type":"content","url":"/compare-r#fitting-smoothing-splines","position":7},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"1. Using smoothing_spline (Python)","lvl2":"Fitting Smoothing Splines"},"type":"lvl3","url":"/compare-r#id-1-using-smoothing-spline-python","position":8},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"1. Using smoothing_spline (Python)","lvl2":"Fitting Smoothing Splines"},"content":"We fit a smoothing spline with a specified degrees of freedom (df=5).\n\n# Fit model\nspl_py = SplineFitter(x=hr_numeric, df=df)\nspl_py.fit(bikers)\n\n# Predict\ny_py = spl_py.predict(x_plot)\n\n\n\n","type":"content","url":"/compare-r#id-1-using-smoothing-spline-python","position":9},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"2. Using smooth.spline (R)","lvl2":"Fitting Smoothing Splines"},"type":"lvl3","url":"/compare-r#id-2-using-smooth-spline-r","position":10},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"2. Using smooth.spline (R)","lvl2":"Fitting Smoothing Splines"},"content":"We fit the same model using R. We transfer the data to R and run the smooth.spline function.\n\n%%R -i hr_numeric -i bikers -o y_r -i df\n# Fit model in R\nfit_r <- smooth.spline(hr_numeric, bikers, df=df)\n\n# Predict at unique hours\n# unique() in R returns unsorted, but we want to match x_plot order\nx_vals <- sort(unique(hr_numeric))\npred_r <- predict(fit_r, x_vals)\ny_r <- pred_r$y\n\n\n\n","type":"content","url":"/compare-r#id-2-using-smooth-spline-r","position":11},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"Comparison","lvl2":"Fitting Smoothing Splines"},"type":"lvl3","url":"/compare-r#comparison","position":12},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"Comparison","lvl2":"Fitting Smoothing Splines"},"content":"Let’s visualize the results. They should be nearly identical.\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(hr_numeric + np.random.normal(0, 0.1, len(hr_numeric)), bikers, \n            s=1, c='lightgray', alpha=0.5, label='Data')\nax.plot(x_plot, y_py, 'b-', lw=3, label='Python (smoothing_spline)', alpha=0.8)\nax.plot(x_plot, y_r, 'r--', lw=3, label='R (smooth.spline)', alpha=0.8)\nax.set_xlabel(\"Hour\")\nax.set_ylabel(\"Number of Bikers\")\nax.set_title(\"Comparison of Smoothing Splines (df={df})\")\nax.legend()\nplt.show()\n\n# Numerical comparison\n# Note: R might handle repeated x values slightly differently (using weights)\n# smoothing_spline handles them naturally in the basis construction.\ndiff = np.mean(np.abs(y_py - y_r))\nprint(f\"Mean Absolute Difference: {diff:.6f}\")\n\n\n\n","type":"content","url":"/compare-r#comparison","position":13},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Speed Comparison"},"type":"lvl2","url":"/compare-r#speed-comparison","position":14},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Speed Comparison"},"content":"We will compare the execution time for fitting the model.\n\n# Python Timing\nt_py = %timeit -o -n 10 -r 3 SplineFitter(x=hr_numeric, df=10).fit(bikers)\n\n# R Timing\n\n\n\n%%R -i hr_numeric -i bikers\nlibrary(microbenchmark)\n# R Timing\nmicrobenchmark(\n  smooth.spline(hr_numeric, bikers, df=10),\n  times=10\n)\n\n\n\n","type":"content","url":"/compare-r#speed-comparison","position":15},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Automatic Tuning with GCV"},"type":"lvl2","url":"/compare-r#automatic-tuning-with-gcv","position":16},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Automatic Tuning with GCV"},"content":"One of the key features of smoothing splines is the automatic selection of the smoothing parameter (\\lambda) using Generalized Cross-Validation (GCV).","type":"content","url":"/compare-r#automatic-tuning-with-gcv","position":17},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"In R","lvl2":"Automatic Tuning with GCV"},"type":"lvl3","url":"/compare-r#in-r","position":18},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"In R","lvl2":"Automatic Tuning with GCV"},"content":"R’s smooth.spline uses GCV (or CV) by default if df and spar are not specified.\n\n%%R\nfit_gcv <- smooth.spline(hr_numeric, bikers, cv=FALSE) # cv=FALSE implies GCV\ncat(\"Selected df (R):\", fit_gcv$df, \"\n\")\ncat(\"Selected lambda (R):\", fit_gcv$lambda, \"\n\")\n\n\n\n","type":"content","url":"/compare-r#in-r","position":19},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"In Python (smoothing_spline)","lvl2":"Automatic Tuning with GCV"},"type":"lvl3","url":"/compare-r#in-python-smoothing-spline","position":20},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl3":"In Python (smoothing_spline)","lvl2":"Automatic Tuning with GCV"},"content":"The smoothing_spline package also supports finding \\lambda that minimizes the GCV score via the solve_gcv method.\n\n# Initialize fitter with data\n# Note: We use the internal C++ fitter for speed if available\nfitter = SplineFitter(x=hr_numeric, knots=np.unique(hr_numeric))\n\n# Solve for GCV\nbest_lam = fitter.solve_gcv(bikers)\nprint(f\"Selected lambda (Python): {best_lam}\")\n\n# Get corresponding df\n# We can access the internal fitter to compute DF for verification\nif fitter._cpp_fitter:\n    best_lam_scaled = best_lam / fitter.x_scale_**3\n    best_df = fitter._cpp_fitter.compute_df(best_lam_scaled)\n    print(f\"Selected df (Python): {best_df}\")\nelse:\n    best_df = \"N/A (C++ extension not available)\"\n\n\n\nWe can now visualize the optimal fit.\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(hr_numeric + np.random.normal(0, 0.1, len(hr_numeric)), bikers, \n            s=1, c='lightgray')\n# fitter is already fitted with best_lam by solve_gcv\nax.plot(x_plot, fitter.predict(x_plot), 'g-', lw=3, label=f'Optimal GCV (df={best_df:.2f})')\nax.set_xlabel(\"Hour\")\nax.set_ylabel(\"Number of Bikers\")\nax.legend()\nplt.show()\n\n\n\n","type":"content","url":"/compare-r#in-python-smoothing-spline","position":21},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Another Example: Log-Transformation"},"type":"lvl2","url":"/compare-r#another-example-log-transformation","position":22},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Another Example: Log-Transformation"},"content":"The relationship between hours and bikers might be better modeled on a log scale, as counts are non-negative and variance often increases with the mean.\n\n# Fit model on log(bikers)\nlog_bikers = np.log(bikers + 1) # Add 1 to avoid log(0)\nspl_log = SplineFitter(x=hr_numeric, df=df)\nspl_log.fit(log_bikers)\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(hr_numeric + np.random.normal(0, 0.1, len(hr_numeric)), log_bikers, \n            s=1, c='lightgray')\nax.plot(x_plot, spl_log.predict(x_plot), 'purple', lw=3, label='Log-Smoothing Spline (df={df})')\nax.set_xlabel(\"Hour\")\nax.set_ylabel(\"Log(Number of Bikers + 1)\")\nax.legend()\nplt.show()\n\n\n\n","type":"content","url":"/compare-r#another-example-log-transformation","position":23},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Synthetic Data Comparison (Reinsch Engine / All Knots)"},"type":"lvl2","url":"/compare-r#synthetic-data-comparison-reinsch-engine-all-knots","position":24},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Synthetic Data Comparison (Reinsch Engine / All Knots)"},"content":"Finally, we compare the speed of both implementations on a synthetic dataset with 500 unique x values. Since we use all unique x values as knots, smoothing_spline automatically selects the efficient Reinsch engine.\n\n# Synthetic data\nn_syn = 500\ndf = 20\nrng = np.random.default_rng(42)\nx_syn = np.sort(rng.uniform(0, 10, n_syn))\ny_syn = np.sin(np.sqrt(x_syn)*2) + rng.normal(0, 1, n_syn)\nx_plot = np.linspace(x_syn.min() - 1, x_syn.max() + 1, 200)\n\n# Python Fitting\nspline = SplineFitter(x=x_syn, df=df)\nspline.fit(y_syn)\ny_plot_py = spline.predict(x_plot)\n\n# Python Timing (using all unique x as knots)\nprint(f\"Python Timing (n={n_syn}, all knots):\")\n%timeit SplineFitter(x=x_syn, df=df).fit(y_syn)\n\n\n\n%%R -i x_syn -i y_syn -i x_plot -o y_plot_R -i df\nlibrary(microbenchmark)\ncat(sprintf(\"R Timing (n=%d):\\n\", length(x_syn)))\n\n# Fit once to inspect knots\nfit_r_syn <- smooth.spline(x_syn, y_syn, df=df, all.knots=TRUE)\nn_knots_r <- fit_r_syn$fit$nk\ny_plot_R = predict(fit_r_syn, x_plot)$y\ncat(sprintf(\"Number of knots used by R: %d\\n\", n_knots_r))\n\nmicrobenchmark(\n  smooth.spline(x_syn, y_syn, df=df, all.knots=TRUE),\n  times=100\n)\n\n\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.scatter(x_syn, y_syn, \n            s=15, c='lightgray', alpha=0.7, label='Data')\nax.plot(x_plot, y_plot_py, 'b-', lw=3, label='Python (smoothing_spline)', alpha=0.8)\nax.plot(x_plot, y_plot_R, 'r--', lw=3, label='R (smooth.spline)', alpha=0.8)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(f\"Comparison of Smoothing Splines (df={df}) - Reinsch Engine\")\nax.legend()\nplt.show()\n\n\n\n","type":"content","url":"/compare-r#synthetic-data-comparison-reinsch-engine-all-knots","position":25},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Synthetic Data Comparison (BSpline Engine / Limited Knots)"},"type":"lvl2","url":"/compare-r#synthetic-data-comparison-bspline-engine-limited-knots","position":26},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Synthetic Data Comparison (BSpline Engine / Limited Knots)"},"content":"R’s smooth.spline automatically reduces the number of knots when N > 49 (typically to around 50-100) to speed up computation. For N=10000, R uses about 200 knots (or more depending on settings).\n\nTo make a fair speed comparison, we can limit the number of knots in Python as well, which triggers the usage of the bspline engine.\n\n# Python Timing with reduced knots\ndf = 20\nn_syn = 10000\nx_syn = np.sort(rng.uniform(0, 10, n_syn))\ny_syn = np.sin(np.sqrt(x_syn)*2) + rng.normal(0, 1, n_syn)\nn_knots_reduced = 500 # Similar to R's behavior\n\n# Fit for plotting\nspline = SplineFitter(x=x_syn, df=df, n_knots=n_knots_reduced)\nspline.fit(y_syn)\ny_plot_py = spline.predict(x_plot)\n\n\n\n%%timeit \nSplineFitter(x=x_syn, df=df, n_knots=n_knots_reduced).fit(y_syn)\n\n\n\n%%R -i x_syn -i y_syn -i n_knots_reduced -o y_plot_R -i df\nlibrary(microbenchmark)\ncat(sprintf(\"R Timing (n=%d):\\n\", length(x_syn)))\n\n# Fit once to inspect knots\nfit_r_syn <- smooth.spline(x_syn, y_syn, df=df, nknots=n_knots_reduced)\ny_plot_R = predict(fit_r_syn, x_plot)$y\nn_knots_r <- fit_r_syn$fit$nk\ncat(sprintf(\"Number of knots used by R: %d\\n\", n_knots_r))\n\nmicrobenchmark(\n  smooth.spline(x_syn, y_syn, df=df, nknots=n_knots_reduced),\n  times=100\n)\n\n\n\nfig, ax = plt.subplots(figsize=(10, 6))\n# Subsample data for plotting if N is large\nplot_idx = np.random.choice(len(x_syn), size=min(len(x_syn), 1000), replace=False)\nax.scatter(x_syn[plot_idx], y_syn[plot_idx], \n            s=5, c='lightgray', alpha=0.5, label='Data (Subsampled)')\nax.plot(x_plot, y_plot_py, 'b-', lw=3, label='Python (smoothing_spline)', alpha=0.8)\nax.plot(x_plot, y_plot_R, 'r--', lw=3, label='R (smooth.spline)', alpha=0.8)\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(f\"Comparison of Smoothing Splines (df={df}) - BSpline Engine\")\nax.legend()\nplt.show()\n\n\n\n","type":"content","url":"/compare-r#synthetic-data-comparison-bspline-engine-limited-knots","position":27},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Performance Note"},"type":"lvl2","url":"/compare-r#performance-note","position":28},{"hierarchy":{"lvl1":"Comparing smoothing_spline with R’s smooth.spline","lvl2":"Performance Note"},"content":"The smoothing_spline package implements efficient O(N) trace calculation using Takahashi’s equations for the bspline engine, matching the algorithmic complexity of R’s smooth.spline for degrees of freedom calculation, which is the costliest part as it involves a Cholesky factorization for each candidate lamval.","type":"content","url":"/compare-r#performance-note","position":29},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension"},"type":"lvl1","url":"/compare-cpp","position":0},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension"},"content":"This document compares the computational performance of the pure Python implementation (SplineFitterPy) and the C++ optimized implementation (SplineFitter) of the smoothing spline fitter.","type":"content","url":"/compare-cpp","position":1},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"Setup"},"type":"lvl2","url":"/compare-cpp#setup","position":2},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"Setup"},"content":"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport sys\nimport os\n\n# Ensure we can import from tests\nsys.path.append(os.path.abspath('..'))\n\nfrom smoothing_spline.fitter import SplineFitter\ntry:\n    from tests.spline_fitter import SplineFitter as SplineFitterPy\nexcept ImportError:\n    print(\"Could not import pure Python SplineFitter from tests.\")\n    SplineFitterPy = None\n\n\n\n","type":"content","url":"/compare-cpp#setup","position":3},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"Speed Comparison at Different Scales"},"type":"lvl2","url":"/compare-cpp#speed-comparison-at-different-scales","position":4},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"Speed Comparison at Different Scales"},"content":"We will measure the time taken to fit the smoothing spline for different numbers of observations (N) and different numbers of knots (K). We will explicitly test the Natural Spline engine (basis form) and the Reinsch engine (when applicable) and the B-Spline engine.\n\ndef benchmark_fitters(ns, n_knots=None, engine='reinsch', python=True):\n    results = {'py': [], 'cpp': []}\n    \n    for n in ns:\n        rng = np.random.default_rng(0)\n        x = np.sort(rng.uniform(0, 10, n))\n        y = np.sin(x) + rng.normal(0, 0.1, n)\n        \n        # Pure Python (always basis form natural spline)\n        if python:\n            start = time.time()\n            fitter_py = SplineFitterPy(x, n_knots=n_knots, df=10)\n            fitter_py.fit(y)\n            results['py'].append(time.time() - start)\n\n        try:\n            start = time.time()\n            # Explicitly request engine\n            fitter_cpp = SplineFitter(x, df=10, n_knots=n_knots, engine=engine)\n            fitter_cpp.fit(y)\n            results['cpp'].append(time.time() - start)\n        except ValueError:\n            # Engine might not be compatible (e.g. reinsch with reduced knots)\n            results['cpp'].append(np.nan)\n            \n    return results\n\n# Sizes to test\nns = [100, 500, 1000, 2000, 5000][:4]\n\n\n\n","type":"content","url":"/compare-cpp#speed-comparison-at-different-scales","position":5},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl3":"1. All Unique X as Knots (K = N)","lvl2":"Speed Comparison at Different Scales"},"type":"lvl3","url":"/compare-cpp#id-1-all-unique-x-as-knots-k-n","position":6},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl3":"1. All Unique X as Knots (K = N)","lvl2":"Speed Comparison at Different Scales"},"content":"When N is small, using all unique x values as knots is feasible.\nWe compare:\n\nPure Python (Natural Spline Basis)\n\nC++ engine='natural' (Natural Spline Basis)\n\nC++ engine='reinsch' (Reinsch Algorithm - O(N))\n\nC++ engine='bspline' (B-Spline Basis)\n\nC++ engine='auto' (Default Selection)\n\nprint(f\"Benchmarking with ns={ns} (All Knots)...\")\nresults_natural = benchmark_fitters(ns, engine='natural')\nresults_py = results_natural['py']\nresults_natural = results_natural['cpp']\nresults_reinsch = benchmark_fitters(ns, engine='reinsch', python=False)['cpp']\nresults_bspline = benchmark_fitters(ns, engine='bspline', python=False)['cpp']\nresults_auto = benchmark_fitters(ns, engine='auto', python=False)['cpp']\n\nfig, ax = plt.subplots(figsize=(10, 6))\nif SplineFitterPy:\n    ax.plot(ns, results_py, 'o-', label='Pure Python')\nax.plot(ns, results_natural, 's-', label=\"C++ 'natural'\")\nax.plot(ns, results_reinsch, '^-', label=\"C++ 'reinsch'\")\nax.plot(ns, results_bspline, 'd-', label=\"C++ 'bspline'\")\nax.plot(ns, results_auto, 'x--', label=\"C++ 'auto'\")\n\nax.set_xlabel('Number of observations (N)')\nax.set_ylabel('Time (seconds)')\nax.set_title('Speed Comparison (K = N)')\nax.legend()\nax.grid(True)\nax.set_yscale('log')\n\n\n\n\n\n","type":"content","url":"/compare-cpp#id-1-all-unique-x-as-knots-k-n","position":7},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl3":"2. Fixed Number of Knots (K=200)","lvl2":"Speed Comparison at Different Scales"},"type":"lvl3","url":"/compare-cpp#id-2-fixed-number-of-knots-k-200","position":8},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl3":"2. Fixed Number of Knots (K=200)","lvl2":"Speed Comparison at Different Scales"},"content":"In practice, for large N, we often limit the number of knots to a fixed K \\ll N.\nengine='reinsch' is not available here (requires K=N). We compare natural, bspline and auto.\n\nns_large = [100, 500, 1000, 1500, 2000, 5000, 10000, 20000, 30000, 50000]\nK = 200\nprint(f\"Benchmarking with large N and K={K}...\")\nresults_fixed_natural = benchmark_fitters(ns_large, n_knots=K, engine='natural', python=False)['cpp']\nresults_fixed_bspline = benchmark_fitters(ns_large, n_knots=K, engine='bspline', python=False)['cpp']\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 6))\nax.plot(ns_large, results_fixed_natural, 's-', label=f\"C++ 'natural' (K={K})\")\nax.plot(ns_large, results_fixed_bspline, 'd-', label=f\"C++ 'bspline' (K={K})\")\n\nax.set_xlabel('Number of observations (N)')\nax.set_ylabel('Time (seconds)')\nax.set_title(f'Speed Comparison (Fixed K={K})')\nax.legend()\nax.grid(True)\nax.set_yscale('log')\n\n\n\n","type":"content","url":"/compare-cpp#id-2-fixed-number-of-knots-k-200","position":9},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"GCV Solve Performance"},"type":"lvl2","url":"/compare-cpp#gcv-solve-performance","position":10},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"GCV Solve Performance"},"content":"Automatic tuning with GCV involves multiple fits (or an optimized path). The C++ extension provides a highly optimized solve_gcv method.\n\nn = 5000\nK = 200\nrng = np.random.default_rng(0)\nx = np.sort(rng.uniform(0, 10, n))\ny = np.sin(x) + rng.normal(0, 0.1, n)\n\n\n\n%%timeit\nfitter = SplineFitter(x, n_knots=K)\nbest_lam = fitter.solve_gcv(y)\n\n\n\n","type":"content","url":"/compare-cpp#gcv-solve-performance","position":11},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"Conclusion"},"type":"lvl2","url":"/compare-cpp#conclusion","position":12},{"hierarchy":{"lvl1":"Performance Comparison: Pure Python vs C++ Extension","lvl2":"Conclusion"},"content":"The C++ extension provides significant speedups, especially as the number of knots or observations increases. This is due to the efficient matrix operations and optimized algorithms implemented in C++ using the Eigen library.","type":"content","url":"/compare-cpp#conclusion","position":13},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy"},"type":"lvl1","url":"/compare-scipy","position":0},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy"},"content":"This document illustrates the differences in boundary behavior and extrapolation between smoothing_spline.SplineFitter and scipy.interpolate.make_smoothing_spline.\n\nWhile both methods fit smoothing splines, smoothing_spline explicitly implements natural cubic splines, which implies that the function should be linear beyond the boundary knots (i.e., the second derivative is zero at the boundaries).\n\nWe will demonstrate this by fitting both models to a dataset and observing their predictions outside the range of the training data.","type":"content","url":"/compare-scipy","position":1},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Setup"},"type":"lvl2","url":"/compare-scipy#setup","position":2},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Setup"},"content":"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import make_smoothing_spline\nfrom smoothing_spline import SplineFitter\n\n# Generate synthetic data\nrng = np.random.default_rng(42)\nn = 50\nx = np.sort(rng.uniform(0, 10, n))\ny = np.sin(x) + rng.normal(0, 0.2, n)\n\n# Define extrapolation range (+/- 50% of data range)\nx_range = x.max() - x.min()\nx_plot = np.linspace(x.min() - 0.5 * x_range, x.max() + 0.5 * x_range, 200)\n\n\n\n","type":"content","url":"/compare-scipy#setup","position":3},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Fitting the Models"},"type":"lvl2","url":"/compare-scipy#fitting-the-models","position":4},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Fitting the Models"},"content":"We will fit both models using a similar regularization strength. Note that the parameterization of \\lambda might differ slightly, but we will try to match the degrees of freedom or visual smoothness for a fair qualitative comparison. Here we fix lam for make_smoothing_spline and use solve_gcv or fixed lambda for SplineFitter.\n\nFor simplicity, let’s fix a lambda value that provides a reasonable smooth fit.\n\n# Fit smoothing_spline\n# We explicitly ask for a specific lambda or let GCV find one.\n# Let's use GCV for smoothing_spline to get a good fit first.\nfitter = SplineFitter(x, n_knots=25)\nlam_best = fitter.solve_gcv(y)\ny_ours = fitter.predict(x_plot)\n\n# Fit scipy.interpolate.make_smoothing_spline\n# scipy's lam is roughly related. We'll try to use a similar value or just pick one that looks good.\n# SciPy documentation says minimizes \\sum w_i (y_i - g(x_i))^2 + lam \\int g''(t)^2 dt\n# Our objective is essentially the same.\n# Note: SplineFitter scales x internally to [0, range]. Scipy does not?\n# Let's just try to match them or show the qualitative difference.\n# We'll calculate the lambda that scipy would use?\n# Let's just fit scipy with a specific lambda to ensure smoothness.\nlam_scipy = 1e-2 # heuristic\nspl_scipy = make_smoothing_spline(x, y, lam=lam_scipy)\ny_scipy = spl_scipy(x_plot)\n\n\n\n","type":"content","url":"/compare-scipy#fitting-the-models","position":5},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Visualization"},"type":"lvl2","url":"/compare-scipy#visualization","position":6},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Visualization"},"content":"Now we plot the data, the fitted curves within the data range, and the extrapolation.\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Plot Data\nax.scatter(x, y, color='black', label='Data', zorder=5)\n\n# Plot smoothing_spline result\nax.plot(x_plot, y_ours, 'b-', linewidth=2, label='smoothing_spline (Natural)')\n\n# Plot scipy result\nax.plot(x_plot, y_scipy, 'r--', linewidth=2, label='scipy.interpolate.make_smoothing_spline')\n\n# Highlight data boundaries\nax.axvline(x.min(), color='gray', linestyle=':', alpha=0.5)\nax.axvline(x.max(), color='gray', linestyle=':', alpha=0.5)\n\nax.set_title('Extrapolation Behavior: Natural vs. SciPy Spline')\nax.legend()\nax.grid(True, alpha=0.3)\nax.set_ylim([-10,10])\n\n\n\n\n\n","type":"content","url":"/compare-scipy#visualization","position":7},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Analysis"},"type":"lvl2","url":"/compare-scipy#analysis","position":8},{"hierarchy":{"lvl1":"Boundary Behavior Comparison: smoothing_spline vs scipy","lvl2":"Analysis"},"content":"As seen in the plot:\n\nsmoothing_spline: The blue line becomes perfectly linear outside the vertical dashed lines (the data boundaries). This is the defining property of a natural cubic spline. The second derivative is zero at the boundary knots, and this zero curvature is maintained during extrapolation.\n\nscipy.interpolate.make_smoothing_spline: The red dashed line usually exhibits cubic extrapolation (it curves away). While make_smoothing_spline solves the smoothing spline objective, the returned B-spline object often extrapolates based on the polynomial form of the end segments, which is not necessarily constrained to be linear unless specific boundary knots or coefficients are enforced. In many statistical contexts, the “natural” boundary condition (linear extrapolation) is preferred to avoid wild oscillations outside the data range.\n\nThis highlights a key feature of the smoothing_spline package: it guarantees safe, linear extrapolation by design.","type":"content","url":"/compare-scipy#analysis","position":9},{"hierarchy":{"lvl1":"Smoothing Spline Documentation"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Smoothing Spline Documentation"},"content":"This repository provides a minimal and efficient implementation of a smoothing spline, similar to smooth.spline in R.\n\nIt is implemented in C++ with python bindings provided by pybind11, offering multiple fitting engines:\n\nReinsch Algorithm: O(N) performance for when knots equal data points (matches R’s smooth.spline).\n\nNatural Spline Basis: Explicit basis construction, suitable for regression splines (K < N).\n\nB-Spline Basis: Efficient banded solver implementation using LAPACK.\n\nSee the table of contents for more details on the theory and comparisons with other implementations.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation"},"type":"lvl1","url":"/theory","position":0},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation"},"content":"This document outlines the theoretical background for the smoothing_spline package, synthesizing concepts from The Elements of Statistical Learning (Hastie, Tibshirani, Friedman), specifically Chapter 5. It also discusses the implementation details (Reinsch form vs. Basis form) and compares the features with R’s smooth.spline.","type":"content","url":"/theory","position":1},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"1. The Smoothing Spline Problem"},"type":"lvl2","url":"/theory#id-1-the-smoothing-spline-problem","position":2},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"1. The Smoothing Spline Problem"},"content":"The goal of smoothing splines is to find a function f(x) that fits the data \\{(x_i, y_i)\\}_{i=1}^N well while remaining smooth. This is formulated as the minimization of a penalized residual sum of squares:\\min_{f} \\sum_{i=1}^N w_i (y_i - f(x_i))^2 + \\lambda \\int [f''(t)]^2 dt\n\nwhere \\lambda \\ge 0 is a smoothing parameter and w_i > 0 are weights.\n\n\\lambda = 0: f becomes an interpolating spline (passes through every point).\n\n\\lambda \\to \\infty: f approaches the weighted linear least squares fit.","type":"content","url":"/theory#id-1-the-smoothing-spline-problem","position":3},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"The Solution: Natural Cubic Spline","lvl2":"1. The Smoothing Spline Problem"},"type":"lvl3","url":"/theory#the-solution-natural-cubic-spline","position":4},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"The Solution: Natural Cubic Spline","lvl2":"1. The Smoothing Spline Problem"},"content":"Remarkably, the solution to this infinite-dimensional optimization problem is a finite-dimensional Natural Cubic Spline with knots at the unique values of x_i.\n\nA natural cubic spline is a piecewise cubic polynomial that is continuous up to its second derivative, and linear beyond the boundary knots (i.e., its second derivative is zero at the boundaries).","type":"content","url":"/theory#the-solution-natural-cubic-spline","position":5},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"2. Matrix Formulation"},"type":"lvl2","url":"/theory#id-2-matrix-formulation","position":6},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"2. Matrix Formulation"},"content":"Since the solution is a linear combination of basis functions, we can write:f(x) = \\sum_{j=1}^N \\theta_j N_j(x)\n\nwhere N_j(x) are the natural cubic spline basis functions.\n\nThe optimization problem reduces to:\\min_{ \\theta} (y - N \\theta)^T W (y - N \\theta) + \\lambda \\theta^T \\Omega_N \\theta\n\nwhere:\n\nN_{ij} = N_j(x_i) is the basis matrix.\n\nW = \\text{diag}(w_1, \\dots, w_N) is the weight matrix.\n\n(\\Omega_N)_{jk} = \\int N_j''(t) N_k''(t) dt is the penalty matrix.\n\nThe solution is a generalized ridge regression:\\hat{\\theta} = (N^T W N + \\lambda \\Omega_N)^{-1} N^T W y","type":"content","url":"/theory#id-2-matrix-formulation","position":7},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"type":"lvl3","url":"/theory#reinsch-form-vs-basis-form","position":8},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"content":"There are three primary ways to compute the solution in our package:","type":"content","url":"/theory#reinsch-form-vs-basis-form","position":9},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"A. The Natural Spline Basis Form (engine='natural')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"type":"lvl4","url":"/theory#a-the-natural-spline-basis-form-engine-natural","position":10},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"A. The Natural Spline Basis Form (engine='natural')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"content":"We explicitly construct the basis matrix N and the penalty matrix \\Omega.\n\nWe use the property that a natural cubic spline is determined by its values and second derivatives at the knots.\n\nOur C++ implementation constructs N efficiently by solving the tridiagonal system that relates second derivatives to values.\n\nWe then solve the linear system (N^T W N + \\lambda \\Omega)\\theta = N^T W y.\n\nUse of this is not recommended as it is much slower. It was written as part of the development process.\n\nWhy Basis Form?\n\nAllows for Regression Splines: We can choose fewer knots than data points (K < N). The math remains identical, but the matrices are smaller (K \\times K instead of N \\times N).\n\nEasier to extend to weighted least squares or other loss functions.","type":"content","url":"/theory#a-the-natural-spline-basis-form-engine-natural","position":11},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"B. The Reinsch Form (engine='reinsch')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"type":"lvl4","url":"/theory#b-the-reinsch-form-engine-reinsch","position":12},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"B. The Reinsch Form (engine='reinsch')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"content":"If knots are placed at every data point (K=N), the solution vector \\mathbf{f} = (f(x_1), \\dots, f(x_N))^T can be found directly without forming N.\\hat{\\mathbf{f}} = (W + \\lambda K)^{-1} W y\n\nwhere K = Q R^{-1} Q^T.\n\nQ is an N \\times (N-2) tridiagonal matrix of second differences.\n\nR is an (N-2) \\times (N-2) tridiagonal matrix.\n\nThis allows solving the system in O(N) time using banded solvers, making it extremely fast for large N. This matches the algorithm used in R’s smooth.spline.","type":"content","url":"/theory#b-the-reinsch-form-engine-reinsch","position":13},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"C. The B-Spline Basis Form (engine='bspline')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"type":"lvl4","url":"/theory#c-the-b-spline-basis-form-engine-bspline","position":14},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"C. The B-Spline Basis Form (engine='bspline')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"content":"Uses the B-spline basis with compact support.\n\nConstructs banded matrices for the normal equations N^T W N and \\Omega_N.\n\nSolves using LAPACK’s dpbsv via scipy. This is the only part scipy is used so direct calls to LAPACK could in theory be used.\n\nEfficient for both K=N and K<N.","type":"content","url":"/theory#c-the-b-spline-basis-form-engine-bspline","position":15},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"D. Automatic (engine='auto')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"type":"lvl4","url":"/theory#d-automatic-engine-auto","position":16},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl4":"D. Automatic (engine='auto')","lvl3":"Reinsch Form vs. Basis Form","lvl2":"2. Matrix Formulation"},"content":"Uses Reinsch form if possible, else uses the B-Spline form.","type":"content","url":"/theory#d-automatic-engine-auto","position":17},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"3. Degrees of Freedom (df)"},"type":"lvl2","url":"/theory#id-3-degrees-of-freedom-df","position":18},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"3. Degrees of Freedom (df)"},"content":"The smoothing parameter \\lambda is abstract. A more intuitive measure of model complexity is the effective degrees of freedom (df).df(\\lambda) = \\text{trace}(\\mathbf{S}_\\lambda)\n\nwhere \\mathbf{S}_\\lambda is the smoother matrix such that \\hat{y} = \\mathbf{S}_\\lambda y.\n\nFor the Reinsch form, we compute the trace in O(N) time using Takahashi’s equations (calculating selected elements of the inverse of a banded matrix via Cholesky decomposition).\n\nFor the Basis form (Natural), we compute the trace of the dense matrix inverse.\n\nFor the B-spline form, we also use Takahashi’s equations on the banded system to compute the trace efficiently in O(N) time.","type":"content","url":"/theory#id-3-degrees-of-freedom-df","position":19},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"3.1. Details on Degrees of Freedom Computation"},"type":"lvl2","url":"/theory#id-3-1-details-on-degrees-of-freedom-computation","position":20},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"3.1. Details on Degrees of Freedom Computation"},"content":"","type":"content","url":"/theory#id-3-1-details-on-degrees-of-freedom-computation","position":21},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Trace of Inverse via Takahashi’s Algorithm","lvl2":"3.1. Details on Degrees of Freedom Computation"},"type":"lvl3","url":"/theory#trace-of-inverse-via-takahashis-algorithm","position":22},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Trace of Inverse via Takahashi’s Algorithm","lvl2":"3.1. Details on Degrees of Freedom Computation"},"content":"Computing the degrees of freedom requires the trace of the smoother matrix S_\\lambda. In the basis form:\\hat{y} = N \\hat{\\theta} = N (N^T W N + \\lambda \\Omega_N)^{-1} N^T W y\n\nThus, S_\\lambda = N (N^T W N + \\lambda \\Omega_N)^{-1} N^T W. Using the cyclic property of the trace:\\text{df}(\\lambda) = \\text{trace}(S_\\lambda) = \\text{trace}((N^T W N + \\lambda \\Omega_N)^{-1} N^T W N)\n\nLet A = N^T W N. We need to compute \\text{trace}((A + \\lambda \\Omega_N)^{-1} A).\n\nFor banded matrices (like those in our B-spline implementation), we can compute this trace efficiently in O(N) time without inverting the full matrix.\n\nLet H = A + \\lambda \\Omega_N. We need \\text{trace}(H^{-1} A).\nSince A and \\Omega_N are banded, H is banded.\nLet H = U^T U be the Cholesky decomposition of H, where U is an upper triangular banded matrix.\nWe need elements of Z = H^{-1} specifically those where A is non-zero. Since A is banded, we only need the elements of Z within the bandwidth of A.\n\nTakahashi’s Equations provide a way to compute the elements of Z within the band of H (which includes the band of A) using a backward recurrence starting from the bottom-right corner.\n\nCompute Z_{NN} = 1 / U_{NN}^2.\n\nIterate backwards from i = N-1 to 1:\n\nCompute off-diagonal elements Z_{ij} inside the band using previously computed Z values and U.\n\nCompute diagonal element Z_{ii}.\n\nOnce we have the band of Z, we can compute the trace of the product Z A efficiently:\\text{trace}(Z A) = \\sum_{i,j} Z_{ij} A_{ji}\n\nSince A is symmetric and banded, the sum only involves indices (i,j) where |i-j| \\le \\text{bandwidth}, which are exactly the elements we computed.","type":"content","url":"/theory#trace-of-inverse-via-takahashis-algorithm","position":23},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Handling Natural Boundary Conditions (The Projection Matrix P)","lvl2":"3.1. Details on Degrees of Freedom Computation"},"type":"lvl3","url":"/theory#handling-natural-boundary-conditions-the-projection-matrix-p","position":24},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Handling Natural Boundary Conditions (The Projection Matrix P)","lvl2":"3.1. Details on Degrees of Freedom Computation"},"content":"The “natural” boundary conditions (zero second derivative at endpoints) imply linear constraints on the B-spline coefficients \\theta.\\theta_0 = w_{s1} \\theta_1 + w_{s2} \\theta_2\n\n\\theta_{N-1} = w_{e1} \\theta_{N-2} + w_{e2} \\theta_{N-3}\n\nThese constraints reduce the number of free parameters from N to N-2.\nWe can express the full parameter vector \\theta as a linear transformation of the reduced parameters \\gamma = (\\theta_1, \\dots, \\theta_{N-2})^T:\\theta = P \\gamma\n\nwhere P is an N \\times (N-2) sparse projection matrix. P is mostly an identity matrix (shifted), with the first row and last row having non-zero entries in the first two and last two columns respectively.\n\nThe optimization problem in terms of \\gamma becomes:\\min_{\\gamma} (y - N P \\gamma)^T W (y - N P \\gamma) + \\lambda \\gamma^T P^T \\Omega_N P \\gamma\n\nThe normal equations are:(P^T N^T W N P + \\lambda P^T \\Omega_N P) \\gamma = P^T N^T W y\n\nLet \\tilde{A} = P^T N^T W N P and \\tilde{\\Omega} = P^T \\Omega_N P. These matrices remain banded (with slightly modified corners).\nWe solve for \\gamma and then reconstruct \\theta = P \\gamma.\n\nOur bspline engine implements this by:\n\nConstructing the full banded matrices N^T W N and \\Omega_N.\n\nApplying the projection P in-place to the bands (modifying the top-left and bottom-right blocks).\n\nSolving the reduced banded system.\n\nUsing Takahashi’s algorithm on the reduced system to compute the degrees of freedom efficiently.","type":"content","url":"/theory#handling-natural-boundary-conditions-the-projection-matrix-p","position":25},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"4. Comparison with R’s smooth.spline"},"type":"lvl2","url":"/theory#id-4-comparison-with-rs-smooth-spline","position":26},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"4. Comparison with R’s smooth.spline"},"content":"Feature\n\nsmooth.spline (R)\n\nsmoothing_spline (Python)\n\nAlgorithm\n\nReinsch Form (O(N))\n\nengine='auto' (selects best), engine='reinsch' (O(N)), engine='natural' (O(NK^2)), engine='bspline' (Banded)\n\nKnots\n\nAll unique x (default) or nknots\n\nAll unique x or specified n_knots\n\nInput \\lambda\n\nVia spar or lambda\n\nVia lamval\n\nInput df\n\nSupported\n\nSupported (via root finding)\n\nAutomatic Tuning\n\nGCV / CV\n\nGCV\n\nWeights\n\nSupported\n\nSupported\n\nDerivatives\n\nBuilt-in\n\nExposed via predict(deriv=...)\n\nExtrapolation\n\nLinear (via predict)\n\nLinear (explicitly handled)","type":"content","url":"/theory#id-4-comparison-with-rs-smooth-spline","position":27},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Key Differences","lvl2":"4. Comparison with R’s smooth.spline"},"type":"lvl3","url":"/theory#key-differences","position":28},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl3":"Key Differences","lvl2":"4. Comparison with R’s smooth.spline"},"content":"Speed: For N=10,000, smooth.spline is faster because it exploits the band structure of the full system. Our implementation allows n_knots < N (Regression Splines), which restores speed (O(N K^2)) and reduces overfitting risk, a feature smooth.spline supports via nknots.\n\nengine='reinsch': Fast O(N) implementation for when knots = unique x. Matches smooth.spline performance.\n\nengine='natural': Uses the natural cubic spline basis. Good for general use and when K < N.\n\nengine='bspline': Uses B-spline basis. Efficient and stable, good for sparse matrices.\n\nSpar (R specific): R uses a scaling parameter spar related to \\lambda. We use raw \\lambda (scaled by x-range cubed for numerical stability).","type":"content","url":"/theory#key-differences","position":29},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"5. References"},"type":"lvl2","url":"/theory#id-5-references","position":30},{"hierarchy":{"lvl1":"Smoothing Splines: Theory and Implementation","lvl2":"5. References"},"content":"Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. 2nd Edition. Springer. (Chapter 5).\n\nGreen, P. J., & Silverman, B. W. (1994). Nonparametric Regression and Generalized Linear Models: A Roughness Penalty Approach. Chapman and Hall/CRC.","type":"content","url":"/theory#id-5-references","position":31}]}